{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Machine Learning to Recommend Ideal Data Plans for Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Megaline aims to modernize its subscriber base by recommending newer plans—Smart or Ultra—based on customer behavior analysis. Utilizing behavior data from subscribers who have already migrated to these plans, we embark on a classification task to develop a model capable of accurately selecting the appropriate plan. With data preprocessing already completed, our focus shifts to model creation. Our objective is to achieve a minimum accuracy threshold of 0.75, as assessed using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open and look through the data file. Path to the file:datasets/users_behavior.csv Download dataset\n",
    "\n",
    "2. Split the source data into a training set, a validation set, and a test set.\n",
    "\n",
    "3. Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study.\n",
    "\n",
    "4. Check the quality of the model using the test set.\n",
    "\n",
    "5. Additional task: sanity check the model. This data is more complex than what you’re used to working with, so it's not an easy task. We'll take a closer look at it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the dataset provides monthly behavioral insights for individual users. The data includes the following information:\n",
    "\n",
    "    * сalls — number of calls,\n",
    "    * minutes — total call duration in minutes,\n",
    "    * messages — number of text messages,\n",
    "    * mb_used — Internet traffic used in MB,\n",
    "    * is_ultra — plan for the current month (Ultra - 1, Smart - 0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset will be partitioned into training, validation, and testing subsets. Both models will undergo training and fine-tuning using the training and validation data to optimize hyperparameters for enhanced accuracy. Following hyperparameter optimization, the models will be assessed using the test subset, and the model exhibiting the highest accuracy will be chosen as the ultimate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, the CSV file \"users_behavior.csv\" will be read and saved into the DataFrame named \"df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain insights into the dataset stored in the DataFrame \"df\", let's examine the first 20 rows followed by general informatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.0</td>\n",
       "      <td>560.51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9619.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.0</td>\n",
       "      <td>344.32</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19898.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.0</td>\n",
       "      <td>437.13</td>\n",
       "      <td>61.0</td>\n",
       "      <td>21523.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56.0</td>\n",
       "      <td>433.07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16702.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108.0</td>\n",
       "      <td>587.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14406.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>22.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2710.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.0</td>\n",
       "      <td>163.62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16870.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79.0</td>\n",
       "      <td>532.62</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19908.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49.0</td>\n",
       "      <td>341.67</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11770.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calls  minutes  messages   mb_used  is_ultra\n",
       "0    40.0   311.90      83.0  19915.42         0\n",
       "1    85.0   516.75      56.0  22696.96         0\n",
       "2    77.0   467.66      86.0  21060.45         0\n",
       "3   106.0   745.53      81.0   8437.39         1\n",
       "4    66.0   418.74       1.0  14502.75         0\n",
       "5    58.0   344.56      21.0  15823.37         0\n",
       "6    57.0   431.64      20.0   3738.90         1\n",
       "7    15.0   132.40       6.0  21911.60         0\n",
       "8     7.0    43.39       3.0   2538.67         1\n",
       "9    90.0   665.41      38.0  17358.61         0\n",
       "10   82.0   560.51      20.0   9619.53         1\n",
       "11   45.0   344.32      13.0  19898.81         0\n",
       "12   51.0   437.13      61.0  21523.58         0\n",
       "13   56.0   433.07      16.0  16702.36         0\n",
       "14  108.0   587.90       0.0  14406.50         1\n",
       "15    6.0    22.13       0.0   2710.09         0\n",
       "16    2.0    18.73       0.0    588.89         0\n",
       "17   26.0   163.62       4.0  16870.34         0\n",
       "18   79.0   532.62      90.0  19908.31         0\n",
       "19   49.0   341.67      81.0  11770.28         1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head(20) is used to display the first 20 rows of the DataFrame df.\n",
    "\n",
    "The output displays the first 20 rows of the DataFrame df, where each row represents a user and each column represents a feature or attribute of that user. The columns include:\n",
    "\n",
    "* calls: the number of calls made by the user\n",
    "* minutes: the total minutes of calls made by the user\n",
    "* messages: the number of messages sent by the user\n",
    "* mb_used: the amount of mobile data used by the user (in megabytes)\n",
    "* is_ultra: a binary indicator (0 or 1) representing whether the user is on the Ultra plan (1) or not (0-Smart Plan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# summary of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame contains no missing values, and the existing data types are appropriate. While the \"calls\" and \"messages\" columns could potentially be integers instead of floats, retaining them as floats will not impact the modeling process. Consequently, no additional data preparation is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two machine learning algorithms: \n",
    "\n",
    "1. Decision Tree \n",
    "2. Random Forest. \n",
    "\n",
    "The models demonstrating the highest accuracy will be selected for final evaluation. They will undergo testing using the test dataset, where their accuracy will be assessed to gauge performance and identify the superior model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"is_ultra\" column denotes the plan utilized by a customer, with a value of 0 representing the Smart plan and 1 representing the Ultra plan. As our objective is to suggest a plan to customers based on their data usage patterns, the \"is_ultra\" column will serve as our target variable. The remaining columns (\"calls\", \"minutes\", \"messages\", \"mb_used\") offer insights into each customer's data consumption behavior, influencing their choice between the Smart and Ultra plans. Thus, these columns will be our feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame include all columns except for 'is_ultra'\n",
    "features = df.drop('is_ultra', axis=1)\n",
    "\n",
    "#target of the DataFrame is the 'is_ultra' column\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code separates the DataFrame into two components:\n",
    "\n",
    "1. Features: This variable contains all columns from the DataFrame except for the 'is_ultra' column. It is obtained by using the drop() function along the 'is_ultra' column axis (axis=1).\n",
    "\n",
    "2. Target: This variable contains only the 'is_ultra' column from the DataFrame. It represents the target variable that we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features DataFrame and target Series data will be segmented into training, validation, and test datasets following a 3:1:1 ratio. Precisely, the training, validation, and test datasets will encompass 60%, 20%, and 20% of the data from features and target, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To divide the given slices into training, \n",
    "#validation, and test datasets, we'll initially separate the training datasets from the validation and test data. \n",
    "#This entails splitting the data into the train datasets and \"other\" datasets. \n",
    "#The \"other\" datasets will encompass 40% of the data, designated for testing, training datasets will retain 60% of the data.\n",
    "features_train, features_other, target_train, target_other  = train_test_split(features, target, test_size=0.4,\\\n",
    "                                                                               random_state=12345)\n",
    "\n",
    "#Split the \"other\" datasets to create the validation and test datasets.\n",
    "#Since the \"other\" dataset account for 40% of the original data and the validation and test datasets \n",
    "#contain 20% of the original data, the\"other\" datasets will be split in half. \n",
    "#test_size parameter set to 0.5 (for 50%).\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_other, target_other, test_size=0.5,\\\n",
    "                                                                            random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code divides the given features and target data into training, validation, and test datasets using the train_test_split function from sklearn.\n",
    "\n",
    "1. Initially, the code splits the features and target data into training datasets (features_train and target_train) and \"other\" datasets (features_other and target_other). The \"other\" datasets contain 40% of the original data and are designated for testing, while the training datasets retain 60% of the data.\n",
    "\n",
    "\n",
    "2. Then, the \"other\" datasets are further split into validation and test datasets (features_valid, features_test, targets_valid, targets_test). Since the \"other\" dataset accounts for 40% of the original data and the validation and test datasets should each contain 20% of the original data, the \"other\" datasets are split in half. This means the test_size parameter is set to 0.5 (or 50%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target column contains binary values (0 or 1), predicting these values constitutes a binary classification task. A decision tree algorithm proves ideal for such tasks. The maximum depth of the tree stands as a critical hyperparameter in this model. Hence, the subsequent code block generates various models with different maximum depths. Subsequently, each model's accuracy is assessed, and the one with the highest accuracy is showcased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=3, random_state=12345)\n",
      "Best Accuracy: 78.54%\n",
      "Best Depth: 3\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model/Learning Algorithm\n",
    "\n",
    "# Initialize\n",
    "best_model = None\n",
    "best_DT_accuracy = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Create various models with different depth values\n",
    "\n",
    "# for loop for changing depth values (range of 1-41)\n",
    "for depth in range(1,41):\n",
    "    \n",
    "    # Create a model, using the provided depth and the same random_state\n",
    "    DT_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    \n",
    "    # Train the model using the training dataset\n",
    "    DT_model.fit(features_train, target_train)\n",
    "    \n",
    "    # Predict the target values of the validation features using the model\n",
    "    DT_predictions_valid = DT_model.predict(features_valid) # get model predictions on validation set\n",
    "    \n",
    "    # Calculate the accuracy, if allowed\n",
    "    try:\n",
    "        accuracy = accuracy_score(target_valid, DT_predictions_valid)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    # Determe best fit\n",
    "    if accuracy > best_DT_accuracy:\n",
    "        best_DT_model = DT_model\n",
    "        best_DT_depth = depth\n",
    "        best_DT_accuracy = accuracy\n",
    "\n",
    "print('Best Model:', best_DT_model)\n",
    "print(f'Best Accuracy: {round(best_DT_accuracy*100,2)}%')\n",
    "print('Best Depth:', best_DT_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code segment conducts an exhaustive search for the optimal Decision Tree model by iterating through various depths and evaluating their performances on a validation set. Initially, placeholders for the best model (best_model), its associated accuracy (best_DT_accuracy), and the corresponding depth (best_depth) are initialized.\n",
    "\n",
    "Within a loop spanning depths from 1 to 40, Decision Tree models are instantiated and trained using a fixed random state. Subsequently, predictions are made on the validation features, and the accuracy of each model is computed by comparing the predicted values with the actual targets. Should any exceptions arise during this process, the loop is halted. If a model's accuracy surpasses the current best accuracy, the model, depth, and accuracy are updated accordingly.\n",
    "\n",
    "Upon completion of the loop, the best-performing model along with its accuracy and depth are displayed. In the specific instance analyzed, the most effective model is a Decision Tree Classifier with a depth of 3, achieving an accuracy of approximately 78.54% on the validation set. This iterative approach facilitates the identification of an optimal depth for the decision tree model, thus mitigating the risks of overfitting or underfitting and enhancing predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model to forecast the target values. The maximum depth and the number of estimators serve as pivotal hyperparameters for this model. The number of estimators corresponds to the quantity of decision trees within the model. To pinpoint the most effective combination of hyperparameters, we'll train and assess models using various values for both the maximum depth and the number of estimators. This entails nested for loops to iterate through specified ranges for each hyperparameter. Subsequently, all generated models will undergo accuracy evaluation, and the Random Forest model exhibiting the highest accuracy will be highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=12, n_estimators=17, random_state=12345)\n",
      "Best Accuracy: 80.56%\n",
      "Best Depth: 12\n",
      "Best n_estimators: 17\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model\n",
    "\n",
    "# Initialize\n",
    "best_model = None\n",
    "best_result = 10000\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "best_score = 0\n",
    "best_RF_accuracy = 0\n",
    "\n",
    "# Create various models with different depth and estimator values\n",
    "\n",
    "# for loop for the number of estimators\n",
    "for est in range(1,21):\n",
    "    \n",
    "    # for loop for the depth value\n",
    "    for depth in range (1, 41):\n",
    "        \n",
    "        # Create a model, using the provided depth, number of estimators, and the same random_state\n",
    "        RF_model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        \n",
    "        # Train the model using the training dataset\n",
    "        RF_model.fit(features_train, target_train)\n",
    "\n",
    "        # Predict the target values of the validation features using the model\n",
    "        RF_predictions_valid = RF_model.predict(features_valid) # get model predictions on validation set\n",
    "       \n",
    "        # Calculate the accuracy, if allowed\n",
    "        try:\n",
    "            accuracy = accuracy_score(target_valid, RF_predictions_valid)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "     # Determe best fit\n",
    "        if accuracy > best_RF_accuracy:\n",
    "            best_RF_model = RF_model\n",
    "            best_RF_accuracy = accuracy\n",
    "            best_RF_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "print('Best Model:', best_RF_model)\n",
    "print(f'Best Accuracy: {round(best_RF_accuracy*100,2)}%')\n",
    "print('Best Depth:', best_RF_depth)\n",
    "print('Best n_estimators:', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model for classification. It iterates through various combinations of the number of estimators (ranging from 1 to 20) and the maximum depth of the trees (ranging from 1 to 40) to find the combination that yields the highest accuracy on a validation dataset.\n",
    "\n",
    "Within the nested loops, a Random Forest model is instantiated and trained on a training dataset (features_train and target_train). Then, predictions are made on a validation dataset (features_valid), and the accuracy of these predictions is calculated using accuracy_score. If the accuracy of the current model is higher than the previously recorded best accuracy, the current model becomes the new best model.\n",
    "\n",
    "Once all combinations have been evaluated, the code prints out the details of the best model found, including its maximum depth (best_RF_depth), the number of estimators (best_est), and the achieved accuracy (best_RF_accuracy).\n",
    "\n",
    "The output indicates that the best model has a maximum depth of 12 and 17 estimators, achieving an accuracy of approximately 80.56%. This model is represented as a RandomForestClassifier instance with the specified parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the optimal hyperparameters for both the decision tree and random forest models have been determined, the best models of each type have been stored as best_DT_model and best_RF_model, respectively. The next step involves assessing these models by employing them to predict the target values of the test datasets and computing the accuracy of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.54%\n"
     ]
    }
   ],
   "source": [
    "# Test the final decision tree model using the valid dataset\n",
    "\n",
    "# Predict the target values\n",
    "DT_validation_predictions = best_DT_model.predict(features_valid)\n",
    "\n",
    "# Calculate the accuracy\n",
    "DT_validation_accuracy = accuracy_score(target_valid, DT_validation_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(DT_validation_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates the final decision tree model's performance using a validation dataset. First, the model predicts the target values based on the features in the validation dataset. Then, the accuracy of these predictions is calculated by comparing them to the true target values from the validation set. The accuracy_score function computes the accuracy by dividing the number of correct predictions by the total number of predictions made. Finally, the code prints out the accuracy result, rounded to two decimal places and presented as a percentage. In this specific case, the result indicates that the decision tree model achieved an accuracy of approximately 78.54% on the validation dataset, signifying that around 78.54% of the predictions made by the model were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Best Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.56%\n"
     ]
    }
   ],
   "source": [
    "# Test the final decision tree model using the valid dataset\n",
    "\n",
    "# Predict the target values\n",
    "RF_validation_predictions = best_RF_model.predict(features_valid)\n",
    "\n",
    "# Calculate the accuracy\n",
    "RF_validation_accuracy = accuracy_score(target_valid, RF_validation_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(RF_validation_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates the performance of the final Random Forest model using a validation dataset. Initially, the model predicts the target values based on the features present in the validation dataset by employing the predict method associated with the best_RF_model, which embodies the trained Random Forest model. Subsequently, the code calculates the accuracy of the model's predictions. This is accomplished by comparing the predicted target values (RF_validation_predictions) to the true target values derived from the validation dataset (target_valid) using the accuracy_score function. The accuracy_score function quantifies accuracy as the proportion of correct predictions to the total number of predictions made. Lastly, the code displays the accuracy result, rounded to two decimal places and expressed as a percentage. In this instance, the output \"Accuracy: 80.56%\" reveals that the Random Forest model attained an accuracy of approximately 80.56% on the validation dataset, indicating that approximately 80.56% of the model's predictions aligned with the actual values in the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.23%\n"
     ]
    }
   ],
   "source": [
    "# Select the best model based on the validation accuracy\n",
    "if DT_validation_accuracy > RF_validation_accuracy:\n",
    "    best_model = DT_model\n",
    "else:\n",
    "    best_model = RF_model\n",
    "    \n",
    "# Test the final selected model using the test dataset\n",
    "test_predictions = best_model.predict(features_test)\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(test_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is selected based on the validation accuracy between the Decision Tree (DT) model and the Random Forest (RF) model. If the accuracy of the Decision Tree model (DT_validation_accuracy) is greater than that of the Random Forest model (RF_validation_accuracy), the best_model variable is assigned the value of the Decision Tree model (DT_model). Otherwise, if the Random Forest model's accuracy is equal to or higher than that of the Decision Tree model, best_model is assigned the value of the Random Forest model (RF_model).\n",
    "\n",
    "Following the selection of the best model, the code proceeds to test the chosen model's performance using a test dataset. Predictions are made on the test dataset using the predict method associated with the best_model. Subsequently, the accuracy of these predictions is calculated by comparing them against the true target values from the test dataset using the accuracy_score function.\n",
    "\n",
    "Finally, the code prints out the accuracy result. The accuracy is rounded to two decimal places and presented as a percentage. The output \"Accuracy: 78.23%\" indicates that the selected model achieved an accuracy of approximately 78.23% on the test dataset. This suggests that approximately 78.23% of the selected model's predictions corresponded with the actual values in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart or Ultra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users are assigned either the Smart or Ultra plan, represented as 0 or 1 in the target datasets or predicted values. Since recommending a plan is a binary classification task, there exists a baseline accuracy achievable by consistently predicting the majority class. This baseline accuracy corresponds to the proportion of the majority class in the dataset.\n",
    "\n",
    "For instance, if the majority class is the Smart plan, the baseline accuracy would be approximately 70%. However, the final decision tree model and random forest model achieved higher accuracies of 78.54% and 80.56%, respectively. These figures notably surpass the 70% baseline accuracy obtained by always suggesting the majority class. Consequently, it is reasonable to employ either of these final trained models to determine the appropriate plan recommendation for each customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, a comprehensive process for model selection and evaluation in a binary classification task involving plan recommendations. It begins by partitioning the dataset into training, validation, and test sets using the train_test_split function. Then, it iteratively explores various depths for decision tree models and combinations of parameters for random forest models to identify the best-performing model on the validation set.\n",
    "\n",
    "The decision tree and random forest models are rigorously assessed, with their respective accuracies computed on the validation set. Subsequently, the final model is selected based on its performance on the validation set, and its accuracy is evaluated on the test set to gauge its real-world effectiveness.\n",
    "\n",
    "Notably, the achieved accuracies of the final models significantly surpass the baseline accuracy derived from predicting the majority class. For instance, if the majority class is the Smart plan, the baseline accuracy would be approximately 70%. However, both the decision tree and random forest models attain accuracies exceeding 78% and 80%, respectively, showcasing their efficacy in making plan recommendations.\n",
    "\n",
    "Ultimately, the results affirm the suitability of either the decision tree or random forest model for determining plan recommendations, as their accuracies substantially outperform the baseline. This underscores the value of employing machine learning models in optimizing plan recommendations for individual customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
